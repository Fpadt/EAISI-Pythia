---
title   : EAISI - Pythia
subtitle: Data Ingestion
author  : "F.J. Padt"
date    : "`r format(Sys.time(), '%B %d, %Y')`"
output  :
  pdf_document:
    df_print: paged
    toc: yes
    toc_depth: 1      
editor_options:
  chunk_output_type: console
  markdown: 
    wrap: 80  
---

\newpage

![](../images/logo.png)

# Purpose

Refresh data sets for the Pythia project from BW OpenHub to Pythia on OneDrive
ET.

::: callout-note
Can be executed outside Ecotone Network as OneDrive ET\Pythia is used
:::

# Setup

```{r}
#| label:  setup
#| eval:   true

# public functions ---------------------------------------------------------
invisible(source("C:/RW/EAISI-Pythia/library/General.R"))

# devtools::load_all(path = "C:/RW/EAISI-Padt")
library("padt")

# lsrc <- "notebooks/05_data_ingestion.R"  
# if( file.exists(lsrc)){source(lsrc)}

# Configuration parameters of Open Hub DSCP_TRAN
FILE_SPEC <- 
  list(
    DELIM        = ';',
    HEADER       = FALSE,
    DATE_FORMAT  = '%Y-%m-%d'
  )

# helper paths
PATH_PA_CNFG <- file.path(pa_getwd(), "config")
PATH_BRZ_SLS <- file.path(pa_getwd(), pa_BSGP[1], pa_AREA[1])
PATH_SLV_SLS <- file.path(pa_getwd(), pa_BSGP[2], pa_AREA[1])
PATH_BRZ_STK <- file.path(pa_getwd(), pa_BSGP[1], pa_AREA[2])
PATH_SLV_STK <- file.path(pa_getwd(), pa_BSGP[2], pa_AREA[2])
PATH_BRZ__MD <- file.path(pa_getwd(), pa_BSGP[1], pa_AREA[4])
PATH_SLV__MD <- file.path(pa_getwd(), pa_BSGP[2], pa_AREA[4])
```

```{r}
#| label: setup Project
#| eval: false

# TODO: if directory exists check if config file needs to be written

# create the root and underlying folders
pa_setup_project_structure(root_dir = "C:/PW/OneDrive/ET/pythia/data")

# set the DTAP environment
pa_set_environment(.environment = "Production")

# test functions
pa_getwd()
View(pa_get_pipelines())
```


# Export & Copy Procedure

## Administration

```{r}
shell.exec(normalizePath(file.path(".", "admin","IB_OB_FLD.xlsx")))
```

## PipeLines

Use following code to check Pipelines and Transformations

```{r}
shell.exec(file.path(PATH_PA_CNFG, "B4_PIPELINE_ORG.csv"))
shell.exec(file.path(PATH_PA_CNFG, "B4_PIPELINE_MOD.csv"))

#View(pa_get_pipelines())
```

# Transaction Data

EPS_DELETE_FILE

e:\usr\sap\stage\DSCP e:\usr\sap\stage\Dynasys\out

## Outbound

### Sales RTP

Transform .csv files in Bronze to .parquet in Silver

```{r}
#| label:   'Sales to Dynasys RTP'
#| comment: 'Ingestion from Bronze (S1B) to Silver (S2S)'
#| eval:    true

fTransform_csv_to_parquet(
  source_path  = PATH_BRZ_SLS,
  output_path  = PATH_SLV_SLS,
  file_pattern = "^DD_SALES_QTY_202[12345].*\\.csv$",
  file_spec    = FILE_SPEC,
  ohdest       = "DSCP_TRAN",
  verbose      = TRUE
)

```

### Sales IPM

Transform .csv files in Bronze to .parquet in Silver

```{r}
#| label:   'Sales to Dynasys 2018'
#| comment: 'Ingestion from Bronze (S1B) to Silver (S2S)'
#| eval:    true

fTransform_csv_to_parquet(
  source_path  = PATH_BRZ_SLS,
  output_path  = PATH_SLV_SLS,
  file_pattern = "^DD_HISTO_QTY_202[12345].*\\.csv$",  
  file_spec    = FILE_SPEC,
  ohdest       = "ZSOP_ASLS",
  verbose      = TRUE
)

```

### Stock

```{r}
#| label:   'Stock from BW' 
#| comment: 'Ingestion from Bronze (S1B) to Silver (S2S)' 
#| eval:    true  

fTransform_csv_to_parquet(
  source_path  = PATH_BRZ_STK,
  output_path  = PATH_SLV_STK,
  file_pattern = "^IMP03SM1.*\\.csv$", 
  file_spec    = FILE_SPEC,  
  ohdest       = "OH_STOCK",
  verbose      = TRUE
)

```

## Inbound

### Sales DYN

-   

Transform .csv files in Bronze to .parquet in Silver

```{r}
#| label:   'Sales from Dynasys 2018'
#| comment: 'Ingestion from Bronze (S1B) to Silver (S2S)'
#| eval:    true

# Helper function with defaults ####
fHelper_Transform <- 
  function(
    .source_path   = PATH_BRZ_SLS,
    .output_path   = PATH_SLV_SLS,
    .file_pattern,
    .file_spec     = FILE_SPEC,
    .ohdest,
    .verbose       = FALSE
  ){
    fTransform_csv_to_parquet(
      source_path  = .source_path,
      output_path  = .output_path,
      file_pattern = .file_pattern,
      file_spec    = .file_spec,
      ohdest       = .ohdest,
      verbose      = .verbose
    )
  }

# Only for forecasts ####
fHelper_Transform(
  .file_pattern = "^SDSFRPR[24]_202(412|501).*\\.csv$",  # delta
  # .file_pattern = "^SDSFRPR[24]_202.*\\.csv$",              # ALL
  .ohdest       = "OH_FRPR1",
  .verbose      = FALSE  
)    

# Complete Actuals from 2024.02 till now ####
# This saves only 1 month of ACTUALS per VERSMON
# TODO: Remove the 4 next load feb!!!!!!!!!
fHelper_Transform(
  .file_pattern = "^SDSFRPR[13]_202(412|501).*\\.csv$",  # delta
  # .file_pattern = "^SDSFRPR[13]_202.*\\.csv$",              # ALL
  .ohdest       = "OH_FRPR2",
  .verbose      = FALSE  
)  

# Create FTYPE 3 and 4 on Latest Actuals ####
# to be used for forecasting
fHelper_Transform(
  .file_pattern = "^SDSFRPR[13]_202(412|501).*\\.csv$",  # delta
  # .file_pattern = "^SDSFRLV[13]_202[45].*\\.csv$", #ALL 
  .ohdest       = "OH_FRPR3",
  .verbose      = FALSE  
) 

```

# Master Data

## Material

### MATERIAL

```{r}
#| label: 'MATERIAL'
#| eval:   true

# !!!!File needs to be Converted to UTF-8

fTransform_csv_to_parquet(
  source_path  = PATH_BRZ__MD,
  output_path  = PATH_SLV__MD,
  file_pattern = "^MD_MATERIAL\\.CSV$",   
  file_spec    = FILE_SPEC,
  ohdest       = "DSCP_MATE",
  verbose      = TRUE
)

```

### MAT_SALES

```{r}
#| label: 'MAT_SALES',
#| eval:   true

fTransform_csv_to_parquet(
  source_path  = PATH_BRZ__MD,
  output_path  = PATH_SLV__MD,
  file_pattern = "^MD_MATERIAL_SALES_ORG\\.CSV$",   
  file_spec    = FILE_SPEC,
  ohdest       = "DSCP_MATS",
  verbose      = TRUE
)

```

### MAT_PLANT

```{r}
#| label: 'MAT_PLANT',
#| eval:   true

fTransform_csv_to_parquet(
  source_path  = PATH_BRZ__MD,
  output_path  = PATH_SLV__MD,
  file_pattern = "^MD_MATERIAL_PLANT\\.CSV$",   
  file_spec    = FILE_SPEC,
  ohdest       = "DSCP_MATP",
  verbose      = TRUE
)

```

### BOMX

```{r}
#| label: 'BOMX',
#| eval:   true

fTransform_csv_to_parquet(
  source_path  = PATH_BRZ__MD,
  output_path  = PATH_SLV__MD,
  file_pattern = "^MD_BOM.*\\.CSV$",   
  file_spec    = FILE_SPEC,
  ohdest       = "DSCP_BOMX",
  verbose      = TRUE
)
```

## Customer

### CUST_SALES

```{r}
#| label: 'CUST_SALES',
#| eval:   true

# !!!! UTF-8 conversion
fTransform_csv_to_parquet(
  source_path  = PATH_BRZ__MD,
  output_path  = PATH_SLV__MD,
  file_pattern = "^MD_SOLD_TO_CUSTOMER\\.CSV$", 
  file_spec    = FILE_SPEC,  
  ohdest       = "DSCP_CUST",
  verbose      = TRUE
)

```

## Plant

### PLANT

```{r}
#| label: 'PLANT',
#| eval:   true

fTransform_csv_to_parquet(
  source_path  = PATH_BRZ__MD,
  output_path  = PATH_SLV__MD,
  file_pattern = "^MD_PLANT\\.CSV$",   
  file_spec    = FILE_SPEC,  
  ohdest       = "DSCP_PLNT",
  verbose      = TRUE
)
```

## Sales Organization

### SALESORG

```{r}
#| label: 'SALESORG',
#| eval:   true

fTransform_csv_to_parquet(
  source_path  = PATH_BRZ__MD,
  output_path  = PATH_SLV__MD,
  file_pattern = "^MD_SALES_ORG\\.CSV$",   
  file_spec    = FILE_SPEC,  
  ohdest       = "DSCP_SORG",
  verbose      = TRUE
)
```

## Promotions

#### PromoNat

```{r}
#| label: 'PROMO'
#| eval:   true

REL_FLDS <- 
  wb_to_df(
    file  = file.path(PS01, "PRM", "PROMONAT.xlsx"),
    sheet = "FIELDS",
    cols  = c(2, 4, 5)
  )                         %>%
  setDT()                   %>%
  .[RELEVANT == "YES", COL] %>%
  sort()

PROMONAT <-
  wb_to_df(
    file  = file.path(PS01, "PRM", "PROMONAT.xlsx"),
    sheet = "PROMONAT",
    cols  = REL_FLDS
  )                                                           %T>%
  write_parquet(
    sink = file.path(
      PS02, "PRM", 
      "PROMONAT.parquet"
    )
  )                                                     

CR_PR_PROMO_CL2_HEADER <- 
  fread(
    file = file.path(PPRM, "CR_PR_PROMO_CL2_HEADER.CSV")
  )

CR_PR_PROMO_CL2_LINE <- 
  fread(
    file = file.path(PPRM, "CR_PR_PROMO_CL2_LINE.CSV")
  )

CR_PR_PROMO_CL3_HEADER <- 
  fread(
    file = file.path(PPRM, "CR_PR_PROMO_CL3_HEADER.CSV")
  )

CR_PR_PROMO_CL3_LINE <- 
  fread(
    file = file.path(PPRM, "CR_PR_PROMO_CL3_LINE.CSV")
  )
```
