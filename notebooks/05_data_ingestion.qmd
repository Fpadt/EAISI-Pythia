---
title   : EAISI - Pythia
subtitle: Data Ingestion
author  : "F.J. Padt"
date    : "`r format(Sys.time(), '%B %d, %Y')`"
output  :
  pdf_document:
    df_print: paged
    toc: yes
    toc_depth: 1      
editor_options:
  chunk_output_type: console
  markdown: 
    wrap: 80  
---

\newpage

![Logo](C:/PW\OneDrive\ET\pythia\img\pythia_logo2_no_text.png)

# Purpose

Refresh data sets for the Pythia project from BW OpenHub to Pythia on PET. The
data sets are used to validate the Pythia model.

This code needs to run in Ecotone Network and SAP should be available

# Setup

```{r}
#| label:  setup
#| eval:   true

knitr::opts_chunk$set(
  cache   = FALSE,
  echo    = TRUE,     # include R source code in the output  
  eval    = TRUE,
  message = FALSE,
  warning = FALSE,
  results = "markup",
  image   = TRUE,  
  include = TRUE      # include the chunk output in the output 
)

SID <- "WPB500"
SYS <- substr(SID, 1, 3)

# SAP Access
# library(reticulate)
# use_condaenv("sapyr")

# public functions ---------------------------------------------------------
invisible(source('library/KnitR_SetUp.R'))

lsrc <- "notebooks/05_data_ingestion.R"  
if( file.exists(lsrc)){source(lsrc)}

```

```{r}
clipr::write_clip(normalizePath(file.path(PS01, SYS, "RTP", "CSV")))
```

# Export & Copy Procedure

## Pythia DTP's

1.  \[15. Min\] DTP_006EIZGR39XAWPP4RBZMZCEU2 PYTHIA -\> IS PERKZ-W \[2021,
    2022, 2023\]
2.  \[05. Min\] DTP_006EIZGR39XAWPP4O3JPT9E6Y PYTHIA -\> IS PERKZ-W \[\>=2024\]
3.  \[02. Min\] DTP_006EIZGR39XAWPP4SWFV127TM PYTHIA -\> OS PERKZ-W
    \[\>=SY-DATE - 60\]

## Export

1.  \[15. Min\] RSPC: LC_DYN_PERKZ_W
2.  \[05. Min\] DTP_006EIZGR39XAWPP4O3JPT9E6Y PYTHIA -\> IS PERKZ-W \[\>=2024\]
3.  AL11 - DSCP E:\USR\SAP\STAGE\DSCP\PERKZ\_W\
4.  save PRTP
    1.  TMP execute next code chunk to change Thousands Separator
5.  

## RTP Sales

```{r}
#| label: 'get Header DD_SALES_QTY'
#| eval:   false
#| 
# HDR <- fread(
#   file = file.path(PS01, SYS, "RTP", "CSV", paste0("S_DD_SALES_QTY.CSV")),
#   header = TRUE, skip=5
#   )
```

```{r}
#| label: 'DuckDB test'
#| eval:   false

# Establish a connection to DuckDB
con <- dbConnect(duckdb(), dbdir = ":memory:")

yr  <- 21
FFNS <- 
  file.path(
    PS01, SYS, "RTP", "CSV", 
    paste0("DD_SALES_QTY_20", yr, ".CSV")
  )

FFNT <- 
  file.path(
    PS02, SYS, "RTP", "ARR", 
    paste0("DD_SALES_QTY_20", yr, ".parquet")
  )

# Define the Source CSV definition
SLS_CSV <- glue_sql("
  read_csv({FFNS},
    delim      = ';',
    header     = false,
    dateformat = '%Y-%m-%d',
    columns = {{
      'MATERIAL'  : 'VARCHAR',
      'CUSTOMER'  : 'VARCHAR',
      'PLANT'     : 'VARCHAR',
      'SALESORG'  : 'VARCHAR',
      'CALDAY'    : 'DATE',
      'SLS_QT_SO' : 'FLOAT',
      'SLS_QT_RET': 'FLOAT',
      'SLS_QT_FOC': 'FLOAT',
      'SLS_QT_DIR': 'FLOAT',
      'SLS_QT_PRO': 'FLOAT',
      'SLS_QT_IC' : 'FLOAT',
      'MSQTBUO'   : 'FLOAT'
    }}
  )", .con = con)

# Use the Source CSV parameter in the main SQL query
sql_01_get_data <- glue_sql("
  SELECT
  *
  FROM
  {SLS_CSV}
  ", .con = con)


# sql_01_get_data <-
#   paste0("
# SELECT
# *
# FROM
# read_csv('", FFNS, "',
# delim      = ';',
# header     = false,
# dateformat = '%Y-%m-%d',
# columns = {
# 'MATERIAL'  : 'VARCHAR',
# 'CUSTOMER'  : 'VARCHAR',
# 'PLANT'     : 'VARCHAR',
# 'SALESORG'  : 'VARCHAR',
# 'CALDAY'    : 'DATE'   ,
# 'SLS_QT_SO' : 'FLOAT'  ,
# 'SLS_QT_RET': 'FLOAT'  ,
# 'SLS_QT_FOC': 'FLOAT'  ,
# 'SLS_QT_DIR': 'FLOAT'  ,
# 'SLS_QT_PRO': 'FLOAT'  ,
# 'SLS_QT_IC' : 'FLOAT'  ,
# 'MSQTBUO'   : 'FLOAT'
# })
# ")



sql_02_transform_data <- 
  paste0(
    "SELECT 
      lpad(MATERIAL, 18, '0')     as MATERIAL  ,
      lpad(CUSTOMER, 10, '0')     as CUSTOMER  ,
      PLANT                       as PLANT     ,
      SALESORG                    as SALESORG  ,
      CALDAY                      as CALDAY    ,
      DATE_TRUNC('month', CALDAY) as CALMONTH,
      SLS_QT_SO                   as SLS_QT_SO ,
      SLS_QT_RET                  as SLS_QT_RET,
      SLS_QT_FOC                  as SLS_QT_FOC,
      SLS_QT_DIR                  as SLS_QT_DIR,
      SLS_QT_PRO                  as SLS_QT_PRO,
      SLS_QT_IC                   as SLS_QT_IC ,
      MSQTBUO                     as MSQTBUO
    FROM 
     (", sql_01_get_data, ")"
  )

sql_22_transform_data <- glue_sql("
  SELECT 
    lpad(MATERIAL, 18, '0')     as MATERIAL,
    lpad(CUSTOMER, 10, '0')     as CUSTOMER,
    PLANT                       as PLANT,
    SALESORG                    as SALESORG,
    CALDAY                      as CALDAY,
    DATE_TRUNC('month', CALDAY) as CALMONTH,
    SLS_QT_SO                   as SLS_QT_SO,
    SLS_QT_RET                  as SLS_QT_RET,
    SLS_QT_FOC                  as SLS_QT_FOC,
    SLS_QT_DIR                  as SLS_QT_DIR,
    SLS_QT_PRO                  as SLS_QT_PRO,
    SLS_QT_IC                   as SLS_QT_IC,
    MSQTBUO                     as MSQTBUO
  FROM 
    ({sql_01_get_data})
  ", .con = con)

sql_03_write_data <- 
  paste0(
    "COPY (", 
    sql_02_transform_data,
    ") TO '",
    FFNT, 
    "'
    (FORMAT 'parquet', CODEC 'uncompressed')"
  )

# # Use glue_sql to build the SQL statement
# sql_33_write_data <- glue_sql("
#   COPY ({sql_02_transform_data})
#   TO {FFNT}
#   (FORMAT 'parquet', CODEC 'uncompressed')
#   ", .con = con)

# Construct the COPY command using glue_sql
sql_33_write_data <- glue_sql("
  COPY (
    {sql_02_transform_data}
  ) TO {FFNT}
  (FORMAT 'parquet', CODEC 'uncompressed')
  ", .con = con)

sql_33_write_data <- glue("
  COPY (
    {sql_02_transform_data}
  ) TO '{FFNT}'
  (FORMAT 'parquet', CODEC 'uncompressed')
  ")

system.time({
dbExecute(con, sql_33_write_data)

dbGetQuery(con, paste0("DESCRIBE SELECT * FROM '", FFNT,  "';"))
})

# Disconnect from DuckDB
dbDisconnect(con, shutdown = TRUE)

```

```{r}
#| label: 'DuckDB old'
#| eval:   false

# Establish a connection to DuckDB
con <- dbConnect(duckdb(), dbdir = ":memory:")


yr  <- 21
FFNS <- 
  file.path(
    PS01, SYS, "RTP", "CSV", 
    paste0("DD_SALES_QTY_20", yr, ".CSV")
  )

FFNT <- 
  file.path(
    PS02, SYS, "RTP", "ARR", 
    paste0("DD_SALES_QTY_20", yr, ".parquet")
  )

# Constants
DELIM <- ';'
HEADER <- FALSE
DATE_FORMAT <- '%Y-%m-%d'

# Define the Source CSV definition
SLS_CSV <- glue_sql("
  read_csv({FFNS},
    delim      = {DELIM},
    header     = {HEADER},
    dateformat = {DATE_FORMAT},
    columns = {{
      'MATERIAL'  : 'VARCHAR',
      'CUSTOMER'  : 'VARCHAR',
      'PLANT'     : 'VARCHAR',
      'SALESORG'  : 'VARCHAR',
      'CALDAY'    : 'DATE',
      'SLS_QT_SO' : 'FLOAT',
      'SLS_QT_RET': 'FLOAT',
      'SLS_QT_FOC': 'FLOAT',
      'SLS_QT_DIR': 'FLOAT',
      'SLS_QT_PRO': 'FLOAT',
      'SLS_QT_IC' : 'FLOAT',
      'MSQTBUO'   : 'FLOAT'
    }}
  )", .con = con)

# Use the Source CSV parameter in the main SQL query
sql_31_get_data <- glue_sql("
  SELECT
  *
  FROM
  {SLS_CSV}
  ", .con = con)

sql_32_transform_data <- glue_sql("
  SELECT 
    lpad(MATERIAL, 18, '0')     as MATERIAL,
    lpad(CUSTOMER, 10, '0')     as CUSTOMER,
    PLANT                       as PLANT,
    SALESORG                    as SALESORG,
    CALDAY                      as CALDAY,
    DATE_TRUNC('month', CALDAY) as CALMONTH,
    SLS_QT_SO                   as SLS_QT_SO,
    SLS_QT_RET                  as SLS_QT_RET,
    SLS_QT_FOC                  as SLS_QT_FOC,
    SLS_QT_DIR                  as SLS_QT_DIR,
    SLS_QT_PRO                  as SLS_QT_PRO,
    SLS_QT_IC                   as SLS_QT_IC,
    MSQTBUO                     as MSQTBUO
  FROM 
    ({sql_31_get_data})
  ", .con = con)

sql_33_write_data <- glue("
  COPY (
    {sql_32_transform_data}
  ) TO '{FFNT}'
  (FORMAT 'parquet', CODEC 'uncompressed')
  ")

system.time({
dbExecute(con, sql_33_write_data)

dbGetQuery(con, paste0("DESCRIBE SELECT * FROM '", FFNT,  "';"))
})

# Disconnect from DuckDB
dbDisconnect(con, shutdown = TRUE)

```

```{r}
#|label: 'working duckDB legacy'
#|eval:   false


library(glue) 
library(DBI) 

# Constants
DELIM <- ';'
HEADER <- FALSE
DATE_FORMAT <- '%Y-%m-%d'

# Column definitions as a constant
COLUMN_DEFINITIONS <- list(
  MATERIAL  = 'VARCHAR',
  CUSTOMER  = 'VARCHAR',
  PLANT     = 'VARCHAR',
  SALESORG  = 'VARCHAR',
  CALDAY    = 'DATE',
  SLS_QT_SO = 'FLOAT',
  SLS_QT_RET = 'FLOAT',
  SLS_QT_FOC = 'FLOAT',
  SLS_QT_DIR = 'FLOAT',
  SLS_QT_PRO = 'FLOAT',
  SLS_QT_IC  = 'FLOAT',
  MSQTBUO    = 'FLOAT'
)

# Define file paths
yr <- 21
FFNS <- file.path(PS01, SYS, "RTP", "CSV", paste0("DD_SALES_QTY_20", yr, ".CSV"))
FFNT <- file.path(PS02, SYS, "RTP", "ARR", paste0("DD_SALES_QTY_20", yr, ".parquet"))

# Generate formatted_columns
formatted_columns <- paste(
  sapply(
    names(COLUMN_DEFINITIONS), 
    function(col) {
      glue("'{col}'  : '{COLUMN_DEFINITIONS[[col]]}'")
    }),
  collapse = ",\n    "
)

# Define the Source CSV definition using glue
SLS_CSV <- glue("
  read_csv('{FFNS}',
    delim      = '{DELIM}',
    header     = {HEADER},
    dateformat = '{DATE_FORMAT}',
    columns = {{
      {formatted_columns}
    }}
  )
")

# Establish a connection to DuckDB
con <- dbConnect(duckdb(), dbdir = ":memory:")


# Use the Source CSV parameter in the main SQL query
sql_get_data <- glue_sql("
  SELECT *
  FROM {DBI::SQL(SLS_CSV)}
  ", .con = con)

# Transform data
sql_transform_data <- glue_sql("
  SELECT 
    lpad(MATERIAL, 18, '0')     as MATERIAL,
    lpad(CUSTOMER, 10, '0')     as CUSTOMER,
    PLANT                       as PLANT,
    SALESORG                    as SALESORG,
    CALDAY                      as CALDAY,
    DATE_TRUNC('month', CALDAY) as CALMONTH,
    SLS_QT_SO                   as SLS_QT_SO,
    SLS_QT_RET                  as SLS_QT_RET,
    SLS_QT_FOC                  as SLS_QT_FOC,
    SLS_QT_DIR                  as SLS_QT_DIR,
    SLS_QT_PRO                  as SLS_QT_PRO,
    SLS_QT_IC                   as SLS_QT_IC,
    MSQTBUO                     as MSQTBUO
  FROM ({DBI::SQL(sql_get_data)})
  ", .con = con)

# Write data to Parquet
sql_write_data <- glue("
  COPY ({sql_transform_data})
  TO '{FFNT}'
  (FORMAT 'parquet', CODEC 'uncompressed')
  ")

# Execute the SQL statements
system.time({
  dbExecute(con, sql_write_data)
  dbGetQuery(con, paste0("DESCRIBE SELECT * FROM '", FFNT, "';"))
})

# Disconnect from the database
dbDisconnect(con)
```


```{r}
#| label: 'Data Ingestion to Silver storage S2S using DuckDB'
#| eval:   true

# Configuration parameters
config <- list(
  DELIM        = ';',
  HEADER       = FALSE,
  DATE_FORMAT  = '%Y-%m-%d',
  COLUMN_DEFINITIONS = list(
    MATERIAL   = 'VARCHAR',
    CUSTOMER   = 'VARCHAR',
    PLANT      = 'VARCHAR',
    SALESORG   = 'VARCHAR',
    CALDAY     = 'DATE',
    SLS_QT_SO  = 'FLOAT',
    SLS_QT_RET = 'FLOAT',
    SLS_QT_FOC = 'FLOAT',
    SLS_QT_DIR = 'FLOAT',
    SLS_QT_PRO = 'FLOAT',
    SLS_QT_IC  = 'FLOAT',
    MSQTBUO    = 'FLOAT'
  )
)

# Function to generate formatted columns
generate_formatted_columns <- function(column_definitions) {
  paste(
    sapply(
      names(column_definitions),
      function(col) {
        glue("'{col}'  : '{column_definitions[[col]]}'")
      }
    ),
    collapse = ",\n    "
  )
}

# Function to generate the read_csv SQL snippet
generate_sls_csv <- function(ffns, delim, header, date_format, formatted_columns) {
  glue("
    read_csv('{ffns}',
      delim      = '{delim}',
      header     = {header},
      dateformat = '{date_format}',
      columns = {{
        {formatted_columns}
      }}
    )
  ")
}

# Function to perform data transformation
transform_data_sql <- function(sls_csv_sql, con) {
  # Use glue_sql to construct SQL query
  sql_get_data <- glue_sql("
    SELECT *
    FROM {DBI::SQL(sls_csv_sql)}
    ", .con = con)
  
  sql_transform_data <- glue_sql("
    SELECT 
      lpad(MATERIAL, 18, '0')     AS MATERIAL,
      lpad(CUSTOMER, 10, '0')     AS CUSTOMER,
      PLANT                       AS PLANT,
      SALESORG                    AS SALESORG,
      CALDAY                      AS CALDAY,
      DATE_TRUNC('month', CALDAY) AS CALMONTH,
      SLS_QT_SO                   AS SLS_QT_SO,
      SLS_QT_RET                  AS SLS_QT_RET,
      SLS_QT_FOC                  AS SLS_QT_FOC,
      SLS_QT_DIR                  AS SLS_QT_DIR,
      SLS_QT_PRO                  AS SLS_QT_PRO,
      SLS_QT_IC                   AS SLS_QT_IC,
      MSQTBUO                     AS MSQTBUO
    FROM ({DBI::SQL(sql_get_data)})
    ", .con = con)
  
  return(sql_transform_data)
}

# Function to write data to Parquet
write_data_to_parquet <- function(sql_transform_data, output_file) {
  sql_write_data <- glue("
    COPY ({sql_transform_data})
    TO '{output_file}'
    (FORMAT 'parquet', CODEC 'uncompressed')
    ")
  
  return(sql_write_data)
}

# Main function to process data
process_data <- function(
    yr, 
    input_base_path, 
    output_base_path, 
    sys_value, 
    verbose = FALSE) {

  # Define file paths
  input_csv_file  <- 
    file.path(
      input_base_path , sys_value, "RTP", "CSV", 
      paste0("DD_SALES_QTY_20", yr, ".CSV")
    )
  output_pqt_file <- 
    file.path(
      output_base_path, sys_value, "RTP", "ARR", 
      paste0("DD_SALES_QTY_20", yr, ".parquet")
    )
  
  # Check if input file exists
  if (!file.exists(input_csv_file)) {
    stop(glue("Input CSV file does not exist: {input_csv_file}"))
  }
  
  # Generate formatted columns
  formatted_columns <- generate_formatted_columns(config$COLUMN_DEFINITIONS)
  
  # Generate SLS_CSV
  sls_csv <- generate_sls_csv(
    ffns = input_csv_file,
    delim = config$DELIM,
    header = config$HEADER,
    date_format = config$DATE_FORMAT,
    formatted_columns = formatted_columns
  )
  
  # Establish a connection to DuckDB
  con <- dbConnect(duckdb(), dbdir = ":memory:")
  
  # Ensure the connection is closed when the function exits
  on.exit(dbDisconnect(con), add = TRUE)
  
  # Generate SQL for data transformation
  sql_transform_data <- transform_data_sql(sls_csv_sql = sls_csv, con = con)
  
  # Generate SQL for writing data
  sql_write_data <- write_data_to_parquet(sql_transform_data, output_pqt_file)
  
  # Execute the SQL statements
  tryCatch({
    system.time({
      dbExecute(con, sql_write_data)
      if (verbose == TRUE){
        print(
          dbGetQuery(con, glue("DESCRIBE SELECT * FROM '{output_pqt_file}';"))
        )
      }
      message(glue("Data successfully written to {output_pqt_file}"))
    })
  }, error = function(e) {
    message(glue("An error occurred: {e$message}"))
  })
}

```

```{r}
#| label: 'Run the main function'
#| eval:   true

yrs <- 24:24                    # Year parameter

# Run the main function
purrr::walk(yrs, process_data, PS01, PS02, SYS, verbose = TRUE)

```


```{r}
#| label: 'Concatenate sales data'
#| eval:   true

fReadHist <- 
  function(yr, bsn){
    fread(
      file = file.path(
        PS01, SYS, "RTP", "CSV", 
        paste0("DD_SALES_QTY_20", yr, ".CSV")
      )
    )
  }

YRS <- c(yr = 21:24)
BNM <- "DD_HISTO_QTY"

system.time({
  SLS <- 
    map(.x = YRS, .f = fReadHist, bsn = BNM)                         %>%
    rbindlist()                                                      %T>%
    setnames(fGet_FieldNames("DSCP_TRAN"))                           %>%
    .[, `:=` (
      MATERIAL   = LP0(MATERIAL, 18),
      CUSTOMER   = LP0(CUSTOMER, 10)    
    )]                                                               %>%
    write_parquet(
      sink = file.path(
        PS02, SYS, "RTP", "ARR", 
        paste0(BSNM, "_", "21-24.parquet")
      )
    )
})
```

```{r}
#| label: 'Concatenate sales data'
#| eval:   true

system.time({
  SLS <- 
    rbind(
      fread(file = file.path(
        PS01, SYS, "RTP", "CSV", 
        "DD_SALES_QTY_LE23.csv")
      )                                                              %>%
        .[V5 < ymd("2024-01-01")],
      fread(file = file.path(
        PS01, SYS, "RTP", "CSV", 
        "DD_SALES_QTY_GE24.csv")
      )                                                              %>%
        .[V5 >= ymd("2024-01-01")]
    )                                                                %T>%
    setnames(fGet_FieldNames("DSCP_TRAN"))                           %>%
    .[, `:=` (
      MATERIAL   = LP0(MATERIAL, 18),
      CUSTOMER   = LP0(CUSTOMER, 10)    
    )]                                                               %>%
    write_parquet(
      sink = file.path(
        PS02, SYS, "RTP", "ARR", 
        "DD_HISTO_QTY_GE21.parquet"
      )
    )
})
```

```{r}
#| label: 'Change Thousand separator'
#| eval:   false

fsubDOT <- 
  function(x){
    sub(pattern = "\\.", replacement = "", x = x)
  }

fsubCOM <- 
  function(x){
    sub(pattern = ",", replacement = ".", x = x)
  }

fas_NUM <- 
  function(x){
    as.numeric(x)
  }

cols <- 
  c("SLS_QT_SO",  "SLS_QT_RET", "SLS_QT_FOC", "SLS_QT_DIR",
    "SLS_QT_PRO", "SLS_QT_IC" , "MSQTBUO"
  )    

SLS <- 
  rbind(
    fread(file = file.path(
      PS01, SYS, "RTP", "CSV", 
      "DD_SALES_QTY_LE23.csv")
    )                                                                %>%
      .[V5 < ymd("2024-01-01")],
    fread(file = file.path(
      PS01, SYS, "RTP", "CSV", 
      "DD_SALES_QTY_GE24.csv")
    )                                                                %>%
      .[V5 >= ymd("2024-01-01")]
  )                                                                  %T>%
  setnames(fGet_FieldNames("DSCP_TRAN"))                             %>%
  .[, `:=` (
    # CALDAY     = ymd(CALDAY)      ,
    MATERIAL   = LP0(MATERIAL, 18),
    # MAT_SALES  = LP0(MATERIAL, 18),
    # MAT_PLANT  = LP0(MATERIAL, 18),      
    # CUST_SALES = LP0(CUSTOMER, 10),
    CUSTOMER   = LP0(CUSTOMER, 10)    
  )]                                                                 %>%
  # .[ , (cols) := lapply(.SD, FUN = fsubDOT), .SDcols = cols]         %>%
  # .[ , (cols) := lapply(.SD, FUN = fsubCOM), .SDcols = cols]         %>%
  # .[ , (cols) := lapply(.SD, FUN = fas_NUM), .SDcols = cols]         %T>%
   write_parquet(
    sink = file.path(
      PS02, SYS, "RTP", "ARR", 
      "_DD_HISTO_QTY_GE21.parquet"
    )
  )

```

## RTP Master Data

### Material

#### MATERIAL

```{r}
#| label: 'MATERIAL'
#| eval:   true

pAREA <- "MATERIAL"
MATERIAL <- 
  fLoadOpenHubExport(
    pAREA = pAREA,  
    pKEY  = c(pAREA),
    pPTH  = file.path(PS01, SYS, "RTP", "CSV")
  )                                                                       %>% 
 .[, MATERIAL:= LP0(MATERIAL, 18)]                                        %T>%
  setcolorder("MATERIAL")                                                 %T>%
  write_parquet(
    sink = file.path(
      PS02, SYS, "RTP", "ARR", 
      paste0(CFG[EXP == "NEW" & AREA == pAREA, BNM], ".parquet")
    )
  )

```

#### MAT_SALES

```{r}
#| label: 'MAT_SALES',
#| eval:   true

pAREA <- "MAT_SALES"
MAT_SALES <- 
  fLoadOpenHubExport(
    pAREA = pAREA,  
    pPTH  = file.path(PS01, SYS, "RTP", "CSV")
  )                                                                       %>%
  .[, DISTR_CHAN:= 10]                                                    %>%
  .[, `:=` (MAT_SALES = LP0(MATERIAL, 18), MATERIAL = NULL)]              %T>%
  setcolorder(c("MAT_SALES", "SALESORG", "DISTR_CHAN"))                   %T>%       
  setkey("MAT_SALES", "SALESORG", "DISTR_CHAN")                           %T>%
  write_parquet(
    sink = file.path(
      PS02, SYS, "RTP", "ARR", 
      paste0(CFG[EXP == "NEW" & AREA == pAREA, BNM], ".parquet")
    )
  )                                                              

```

#### MAT_PLANT

```{r}
#| label: 'MAT_PLANT',
#| eval:   true

pAREA <- "MAT_PLANT"
MAT_PLANT <- 
  fLoadOpenHubExport(
    pAREA = pAREA,  
    pKEY  = c("MAT_PLANT", "PLANT"),
    pPTH  = file.path(PS01, SYS, "RTP", "CSV")
  )                                                                       %>%
  .[, `:=` (MAT_PLANT = LP0(MAT_PLANT, 18))]                              %T>%
  setcolorder(c("MAT_PLANT", "PLANT"))                                    %T>%       
  setkey("MAT_PLANT", "PLANT")                                            %T>%
  write_parquet(
    sink = file.path(
      PS02, SYS, "RTP", "ARR", 
      paste0(CFG[EXP == "NEW" & AREA == pAREA, BNM], ".parquet")
    )
  ) 
```

### Customer

#### CUST_SALES

```{r}
#| label: 'CUST_SALES',
#| eval:   true

pAREA <- "SOLDTO"
CUST_SALES <- 
  fLoadOpenHubExport(
    pAREA = pAREA,  
    # pKEY  = c("MAT_PLANT", "PLANT"),
    pPTH  = file.path(PS01, SYS, "RTP", "CSV")
  )                                                                       %>%
  .[, `:=` (
    CUST_SALES = LP0(CUSTOMER  , 10), 
    CUSTHIE04  = LP0(CUSTHIE04 , 10), 
    CUST_HIE03 = LP0(CUST_HIE03, 10), 
    CUST_HIE02 = LP0(CUST_HIE02, 10), 
    CUST_HIE01 = LP0(CUST_HIE01, 10),     
    DISTR_CHAN = 10, 
    CUSTOMER   = NULL
    )]                                                                    %T>%
  setcolorder(c("CUST_SALES", "SALESORG", "DISTR_CHAN"))                  %T>%         
  setkey("CUST_SALES", "SALESORG", "DISTR_CHAN")                          %T>%
  write_parquet(
    sink = file.path(
      PS02, SYS, "RTP", "ARR", 
      paste0(CFG[EXP == "NEW" & AREA == pAREA, BNM], ".parquet")
    )
  ) 
```

### Stock

```{r}
#| label: 'Stock'
#| eval:   true

pAREA <- "STOCK"
STK <- 
  fLoadOpenHubExport(
    pAREA = pAREA,  
    # pKEY  = c("MAT_PLANT", "PLANT"),
    pPTH  = file.path(PS01, SYS, "STK", "CSV")
  )                                                              %T>%         
  setkey("CALDAY", "MATERIAL", "PLANT")                          %T>%
  write_parquet(
    sink = file.path(
      PS02, SYS, "STK", "ARR",
      paste0(CFG[EXP == "NEW" & AREA == pAREA, BNM], ".parquet")
    )
  ) 

```

### Promotions

#### PromoNat

```{r}
#| label: 'PROMO'
#| eval:   true

REL_FLDS <- 
  wb_to_df(
    file  = file.path(PS01, "PRM", "PROMONAT.xlsx"),
    sheet = "FIELDS",
    cols  = c(2, 4, 5)
  )                         %>%
  setDT()                   %>%
  .[RELEVANT == "YES", COL] %>%
  sort()

PROMONAT <-
  wb_to_df(
    file  = file.path(PS01, "PRM", "PROMONAT.xlsx"),
    sheet = "PROMONAT",
    cols  = REL_FLDS
  )                                                           %T>%
  write_parquet(
    sink = file.path(
      PS02, "PRM", "ARR", 
      "PROMONAT.parquet"
    )
  )                                                     

CR_PR_PROMO_CL2_HEADER <- 
  fread(
    file = file.path(PPRM, "CR_PR_PROMO_CL2_HEADER.CSV")
  )

CR_PR_PROMO_CL2_LINE <- 
  fread(
    file = file.path(PPRM, "CR_PR_PROMO_CL2_LINE.CSV")
  )

CR_PR_PROMO_CL3_HEADER <- 
  fread(
    file = file.path(PPRM, "CR_PR_PROMO_CL3_HEADER.CSV")
  )

CR_PR_PROMO_CL3_LINE <- 
  fread(
    file = file.path(PPRM, "CR_PR_PROMO_CL3_LINE.CSV")
  )
```
